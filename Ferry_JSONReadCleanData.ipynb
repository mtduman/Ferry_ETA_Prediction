{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time : Wed Jun  7 01:28:12 2017\n",
      "Data Cleaning start  Time: 0.001940011978149414\n",
      "Original Total Records df.shape[0] 2441553  Time: 28.800361156463623\n",
      "After Filter for (InService,Stopped,abbrev.snull) Total Records df.shape[0] 685817  Time: 30.68649911880493\n",
      "After Filter for (TripTime=0) Total Records df.shape[0] 685349  Time: 45.88225317001343\n",
      "Before remove (Trip end location - Aterm dock distance) > 1000m Trips  df.shape[0] 685349  Time: 75.79079699516296\n",
      "After  remove (Trip end location - Aterm dock distance) > 1000m Trips  df.shape[0] 670983  Time: 77.13331198692322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/groupby.py:1611: FutureWarning: pd.expanding_std is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.expanding(min_periods=1).std()\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Remove Problem Trips xdf.shape[0] 670983  Time: 127.708092212677\n",
      "After Date Filter xdf.shape[0] 670806  Time: 128.1916160583496\n",
      "After  Removed Probled Trips xdf.shape[0] 667061  Time: 138.5887520313263\n",
      "Total time used : 186.3083291053772\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def MergeFiles(xFilesPath, xOrigData) :\n",
    "    df    = pd.DataFrame()\n",
    "    first = True \n",
    "    os.chdir(xFilesPath) \n",
    "    for infile_name in glob.glob('*.json'): \n",
    "        with open(infile_name) as infile:\n",
    "            try:\n",
    "                d               = json.load(infile)\n",
    "                df              = pd.DataFrame(d[\"vessellist\"])\n",
    "                df['timestamp'] = d['timestamp']\n",
    "                if first:\n",
    "                    df.to_csv(xOrigData, mode='w', header=True, index=False)\n",
    "                    first = False\n",
    "                else:\n",
    "                    df.to_csv(xOrigData, mode='a', header=False, index=False)\n",
    "            except:\n",
    "                print(\"Problem on the file:\" ,infile_name)\n",
    "                continue\n",
    "    \n",
    "def CleanOrigData(xOrigData, xAllTrip, xDockLatLon):\n",
    "    print('Data Cleaning start',' Time:', time.time() - start)\n",
    "    df = pd.read_csv(xOrigData,header=0)\n",
    "    print('Original Total Records df.shape[0]',  df.shape[0] , ' Time:', time.time() - start) \n",
    "    df = df[ df.inservice              == True     ]   # if vessel in service\n",
    "    df = df[ df.headtxt               != \"Stopped\" ]   # if vessele stopped waiting\n",
    "    df = df[ df.aterm_abbrev.isnull() == False     ]   # transferring vessle in another dock\n",
    "    df = df[ df.aterm_abbrev          != ''        ]   # transferring vessle in another dock\n",
    "    print('After Filter for (InService,Stopped,abbrev.snull) Total Records df.shape[0]',  df.shape[0], ' Time:', time.time() - start) \n",
    "    \n",
    "    df['timestamp']  = pd.to_datetime(df['timestamp'],                                                               format=\"%m/%d/%Y %I:%M:%S   %p\" )\n",
    "    df['n_datetime'] = pd.to_datetime(df['timestamp'].dt.year.astype(str) + '/' + df['datetime'].astype(str),        format=\"%Y/%m/%d   %H:%M\")  # Use n_leftdock Date info for n_datetime\n",
    "    df['n_leftdock'] = pd.to_datetime(df['n_datetime'].dt.date.astype(str)+ ' ' + df['leftdock']+df['leftdockAMPM'], format=\"%Y-%m-%d %I:%M%p\")\n",
    "    df['n_time_past']= ( ( df['n_datetime'] - df['n_leftdock'] ) / np.timedelta64(1, 'm')).astype(int)\n",
    "    df               = df[ df.n_time_past != -1 ]                                                                          # For leftdock earlier than datetime problem; trip n_datetime 1 minute earlier than n_leftdock\n",
    "    df.loc[df.n_leftdock > df.n_datetime, 'n_leftdock'] = df.n_leftdock - np.timedelta64(1,'D')                            # For trip start before midnight and continue next day n_leftdock calc is wrong; to correct it\n",
    "    df['n_time_past']= ( df['n_datetime'] - df['n_leftdock'] ).astype('timedelta64[m]').astype(int) + 1                    # Now we calculate again the past time, because same n_leftdock info changed , Add 1 MIN, cause we don't know starting time in second\n",
    "    df['n_time_trip']= df.groupby(['vesselID','n_leftdock','lastdock_id'])['n_time_past'].transform(max) + 1               # Add 1 MIN, cause after last record Ferry is moving to Aterm dock\n",
    "    \n",
    "    df['n_arrive']= df.groupby(['vesselID','n_leftdock','lastdock_id'])['n_datetime'].transform(max)+np.timedelta64(1,'m')  # Ferry arrival time columns for all rows\n",
    "    df = df[ df.n_time_trip > 2 ]\n",
    "\n",
    "    print('After Filter for (TripTime=0) Total Records df.shape[0]',  df.shape[0],' Time:', time.time() - start) \n",
    "    df['n_time_left']    = ( df['n_time_trip'] - df['n_time_past'] )\n",
    "############ Put lastdock_LatLon 'LDlat, LDlon' , and aterm_latlon 'ATlat, ATlon'  information to the records for distance calculations\n",
    "    xdf_dock = pd.read_csv(xDockLatLon,header=0)                                   # Read the dock lat,lon info\n",
    "    for ind, row in xdf_dock.iterrows():\n",
    "        df.loc[ (df['lastdock_abbrev']== row['lastdock_abbrev']), 'LD_lat' ] = row['lastdock_lat']\n",
    "        df.loc[ (df['lastdock_abbrev']== row['lastdock_abbrev']), 'LD_lon' ] = row['lastdock_lon']\n",
    "        df.loc[ (df['aterm_abbrev']   == row['aterm_abbrev']   ), 'AT_lat' ] = row['aterm_lat']   \n",
    "        df.loc[ (df['aterm_abbrev']   == row['aterm_abbrev']   ), 'AT_lon' ] = row['aterm_lon']       \n",
    "############ Add Previous TimePast to current record\n",
    "    df.sort_values(['vesselID', 'n_datetime'], ascending=[1,1], inplace=True )\n",
    "    df['p_time_past'] = df.groupby(['vesselID', 'n_leftdock', 'lastdock_id'])['n_time_past'].apply(lambda x: x.shift(1) )\n",
    "    df['p_time_past'].fillna(value=0, inplace=True )    \n",
    "############ Add Previous lat,lon to the current  record\n",
    "    df.sort_values(['vesselID', 'n_datetime'], ascending=[1,1], inplace=True )\n",
    "    df['p_lat'] = df.groupby(['vesselID', 'n_leftdock', 'lastdock_id'])['lat'].apply(lambda x: x.shift(1) )\n",
    "    df['p_lon'] = df.groupby(['vesselID', 'n_leftdock', 'lastdock_id'])['lon'].apply(lambda x: x.shift(1) )\n",
    "############ TRIP first record location's previous lat,lon is the LastDock Lat,Lon add this to the Trip first record\n",
    "    df.p_lat.fillna(df.LD_lat, inplace=True)\n",
    "    df.p_lon.fillna(df.LD_lon, inplace=True)\n",
    "############ Ferry distance(meter) calculation from current loc to prev location\n",
    "    df['n_dist_prevloc'] = 6371 * 1000 * 2 * np.arcsin(\n",
    "        np.sqrt(\n",
    "            np.sin((np.radians(df['p_lat']) - np.radians(df['lat']))/2)**2 \n",
    "            + np.cos(np.radians(df['lat'])) \n",
    "            * np.cos(np.radians(df['p_lat'])) \n",
    "            * np.sin( (np.radians(df['p_lon']) - np.radians(df['lon']))/2)**2\n",
    "                ))\n",
    "############ Ferry's distance from last dock CUMULATIVE\n",
    "    df.sort_values(['vesselID', 'n_datetime'], ascending=[1,1], inplace=True )\n",
    "    df['n_dist_past'] = df.groupby(['vesselID', 'n_leftdock']).n_dist_prevloc.cumsum()\n",
    "    df['n_distTot']   = df.groupby(['vesselID', 'n_leftdock'])['n_dist_past'].transform(max)\n",
    "\n",
    "    df['DistAterm'] = 6371 * 1000 * 2 * np.arcsin(\n",
    "        np.sqrt(\n",
    "            np.sin((  np.radians( df['AT_lat'] ) - np.radians( df['lat'] ))/2)**2 \n",
    "            + np.cos( np.radians( df['lat']    )) \n",
    "            * np.cos( np.radians( df['AT_lat'] )) \n",
    "            * np.sin((np.radians( df['AT_lon'] ) - np.radians( df['lon'] ))/2)**2 ))\n",
    "    df['DistLastdock'] = 6371 * 1000 * 2 * np.arcsin(\n",
    "        np.sqrt(\n",
    "            np.sin((  np.radians( df['LD_lat'] ) - np.radians( df['lat'] ))/2)**2 \n",
    "            + np.cos( np.radians( df['lat']    )) \n",
    "            * np.cos( np.radians( df['LD_lat'] )) \n",
    "            * np.sin((np.radians( df['LD_lon'] ) - np.radians( df['lon'] ))/2)**2 ))\n",
    "    df['DistTripLastLocTOAterm']   = df.groupby(['vesselID', 'n_leftdock'])['DistAterm'].transform('last')\n",
    "############ REMOVE whole Trip records which has last location to Aterm dock distance greater than 1000 meter (Last loc we are useing as a arrival time)\n",
    "############ Trip could be in wrong route (many sample we have)\n",
    "    print('Before remove (Trip end location - Aterm dock distance) > 1000m Trips  df.shape[0]',  df.shape[0], ' Time:', time.time() - start)      \n",
    "    zdf = df[df.DistTripLastLocTOAterm >= 1000]\n",
    "############ Save file those will be removed \n",
    "    zdf.to_csv('/Users/ekinezgi/Documents/FerryProject/tmp/DistTripLastLocTOAterm_over1000m.csv', mode='w', header=True, index=False)\n",
    "    df = df[ df.DistTripLastLocTOAterm < 1000 ]  \n",
    "    print('After  remove (Trip end location - Aterm dock distance) > 1000m Trips  df.shape[0]',  df.shape[0], ' Time:', time.time() - start)\n",
    "############ Generate All Trips Summary info\n",
    "    df.sort_values(  ['lastdock_abbrev','aterm_abbrev','n_leftdock','name'] , ascending=[1,1,1,1], inplace=True ) \n",
    "    ydf = df.groupby(['lastdock_abbrev','aterm_abbrev','n_leftdock','name']).agg({\n",
    "                                'lat'        :{'Flat':'first','Llat':'last' },\n",
    "                                'lon'        :{'Flon':'first','Llon':'last' },\n",
    "                                'name'       :{'Name':'first'},\n",
    "                                'n_leftdock' :{'Record':'count'  },\n",
    "                                'n_distTot'  :{'Distance':'first'},\n",
    "                                'n_time_trip':{'TripDur':'first' },\n",
    "                                'n_arrive'   :{'Arrive':'first'  },\n",
    "                                'speed'      :{'SpeedAvrg':'mean'  }\n",
    "                                }) \n",
    "    ydf.columns = ydf.columns.droplevel()    # drop a level from a multi-level column index\n",
    "    ydf.reset_index(inplace=True)            # Turn Multi-index into column\n",
    "    ydf.to_csv(xAllTrip, mode='w', header=True, index=False)\n",
    "############ Create TimeStampInSec time in the second of the day timestamp and add next TimeStamp to the current location record\n",
    "    df['TimeStampInSec'] = df.timestamp.dt.hour.astype(int)*3600 + df.timestamp.dt.minute.astype(int)*60 + df.timestamp.dt.second.astype(int)\n",
    "    df.sort_values(['vesselID', 'n_datetime'], ascending=[1,1], inplace=True )\n",
    "    df['p_TimeStampInSec'] = df.groupby(['vesselID', 'n_leftdock', 'lastdock_id'])['TimeStampInSec'].apply(lambda x: x.shift(1) )\n",
    "    df.p_TimeStampInSec.fillna( df.TimeStampInSec, inplace=True )\n",
    "############ Trip Count - Time Average and Latency\n",
    "    df['n_Count']  = df.groupby(['vesselID', 'n_leftdock']).speed.cumcount()+1\n",
    "    df['TripAvg']  = df.groupby(['lastdock_abbrev', 'aterm_abbrev'])['n_time_trip'].transform('mean').round()\n",
    "    df['Latency']  = df['n_time_trip'] - df['TripAvg']\n",
    "############ Trip Speed Average\n",
    "    df.sort_values(['vesselID','n_leftdock','n_datetime'], ascending=[1,1,1], inplace=True )\n",
    "    df['SpeedAvg']       = df.groupby(['lastdock_abbrev', 'aterm_abbrev'])['speed'].transform('mean')\n",
    "    df['n_SpeedCumsum']  = df.groupby(['vesselID', 'n_leftdock']).speed.cumsum() \n",
    "    df['n_SpeedCumAvg']  = df['n_SpeedCumsum'] / df['n_Count']\n",
    "    df['n_SpeedTripAvg'] = df.groupby(['vesselID', 'n_leftdock'])['speed'].transform('mean')\n",
    "############ WSF own ETA etaArrival etaDuration and etaTimeLeft\n",
    "    df.loc[df.eta == 'Calculating', 'eta'] = np.NaN    \n",
    "    df.sort_values(['vesselID', 'n_leftdock', 'lastdock_id','n_datetime'], ascending=[1,1,1,0], inplace=True )\n",
    "    df['eta']         = df.groupby(['vesselID', 'n_leftdock', 'lastdock_id'])['eta'    ].fillna(method='ffill')\n",
    "    df['etaAMPM']     = df.groupby(['vesselID', 'n_leftdock', 'lastdock_id'])['etaAMPM'].fillna(method='ffill')\n",
    "    df['etaArrival']  = pd.to_datetime(df['n_arrive'].dt.date.astype(str) + \" \" + df['eta'] + df['etaAMPM'], format=\"%Y-%m-%d %I:%M%p\")\n",
    "    ##### For ETA arrival after midnight\n",
    "    df.loc[df.etaArrival > df.n_arrive + np.timedelta64(1380,'m')  , 'etaArrival'] = df.etaArrival - np.timedelta64(1,'D')       # For trip start before midnight and continue next day n_leftdock calc is wrong; to correct it\n",
    "    df['etaTripDur']  = ( df['etaArrival'] - df['n_leftdock'] ).astype('timedelta64[m]').astype(int) \n",
    "    df['etaTimeLeft'] = df['etaTripDur'] - df['n_time_past'] \n",
    "############ Running-Cummulative Standard Deviation\n",
    "    df['RunStdDev']  =  df.groupby(['n_leftdock'])['speed'].apply(pd.expanding_std)\n",
    "    df['RunStdDev'].fillna(value=0, inplace=True )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def RemoveProblemTrips(xdf, xStartD, xEndD):    \n",
    "    print('Before Remove Problem Trips xdf.shape[0]', xdf.shape[0], ' Time:', time.time() - start)\n",
    "    Remove_df = xdf[ (xdf.n_leftdock < xStartD ) | (xdf.n_leftdock > xEndD ) ]\n",
    "    Remove_df.to_csv('/Users/ekinezgi/Documents/FerryProject/tmp/DateFilterRemovedRecords.csv', mode='w', header=True, index=False)\n",
    "    xdf = xdf[ (xdf.n_leftdock >= xStartD ) & (xdf.n_leftdock <= xEndD ) ]\n",
    "    print('After Date Filter xdf.shape[0]', xdf.shape[0], ' Time:', time.time() - start)\n",
    "    xFilter = [['FRH','SID','2017-01-02 09:55:00'],['FRH','SID','2017-01-02 09:55:00'],['SID','FRH','2017-01-07 12:04:00'], \n",
    "               ['LOP','SHI','2017-02-08 21:55:00'],['LOP','SHI','2017-02-18 20:27:00'],['LOP','SHI','2017-02-23 20:24:00'],\n",
    "               ['LOP','SHI','2017-02-08 16:00:00'],['LOP','SHI','2017-02-23 13:53:00'],['ORI','LOP','2017-02-13 13:25:00'], \n",
    "               ['SOU','FAU','2017-01-26 01:41:00'],['SOU','FAU','2017-03-12 23:06:00'],['SOU','FAU','2017-01-17 23:06:00'],\n",
    "               ['SOU','FAU','2017-01-02 23:07:00'],['SOU','FAU','2017-01-19 00:26:00'],['SOU','FAU','2017-02-02 17:53:00'],\n",
    "               ['SOU','FAU','2017-03-12 01:41:00'],['SHI','ORI','2017-02-10 16:01:00'],['PTD','TAH','2017-02-12 21:31:00'],\n",
    "               ['SHI','ORI','2017-02-14 07:00:00'],['SHI','ORI','2017-02-19 18:28:00'],['SHI','ORI','2017-01-24 12:20:00'],\n",
    "               ['SHI','ORI','2017-03-08 07:00:00'],['FRH','SHI','2017-01-09 06:17:00'] ] \n",
    "    xdf = xdf[ ~((xdf.lastdock_abbrev == 'ORI') & (xdf.aterm_abbrev == 'SHI') ) ]   # 2.\n",
    "    for val in xFilter:\n",
    "        xdf = xdf[ ~((xdf.lastdock_abbrev == val[0]) & (xdf.aterm_abbrev == val[1]) &  \n",
    "                 (xdf.n_leftdock == pd.to_datetime( val[2] ))) ]\n",
    "    print('After  Removed Probled Trips xdf.shape[0]', xdf.shape[0], ' Time:', time.time() - start)\n",
    "    return xdf\n",
    "\n",
    "def CreateFerryData(xdf, xCleanData):   \n",
    "#### Create Dataframe with only selected variables\n",
    "    ydf = xdf[['aterm','aterm_abbrev','aterm_id','datetime','departDelayed','eta','etaAMPM','etaBasis',\n",
    "        'id','inservice','lastdock','lastdock_abbrev','lastdock_id','lat','lon','leftdock',\n",
    "        'leftdockAMPM','name','nextdep','nextdepAMPM','route','speed','system','vesselID','timestamp',\n",
    "        'h','head','headtxt','icon','label','mmsi','old','pos','w','xOffSet','yOffSet',\n",
    "        'n_datetime','n_leftdock','n_time_past','n_arrive','n_time_trip',\n",
    "        'n_time_left','p_lat','p_lon','n_dist_prevloc','n_dist_past','n_distTot',\n",
    "        'TimeStampInSec', 'DistAterm','DistTripLastLocTOAterm','AT_lat','AT_lon','DistLastdock',\n",
    "        'p_time_past','p_TimeStampInSec','TripAvg','Latency','n_Count',\n",
    "        'etaArrival','etaTripDur','etaTimeLeft','RunStdDev','n_SpeedCumAvg','n_SpeedTripAvg','SpeedAvg']]    \n",
    "    ydf.to_csv(xCleanData, mode='w', header=True, index=False)\n",
    "\n",
    "def run():\n",
    "    vDockLatLon = '/Users/ekinezgi/Documents/FerryProject/DockLatLon.csv'\n",
    "\n",
    "# 2017Jan01 - 2017Mar17\n",
    "    vStartD = pd.to_datetime('2017-01-01')\n",
    "    vEndD   = pd.to_datetime('2017-03-18')\n",
    "    vFilesPath  = '/Users/ekinezgi/Downloads/FerryData2017Jan01TOMar17/'\n",
    "    vOrigData   = '/Users/ekinezgi/Documents/FerryProject/2017JanMar_Orig.csv'\n",
    "    vCleanData  = '/Users/ekinezgi/Documents/FerryProject/2017JanMar_Data.csv'\n",
    "    vAllTrip   = '/Users/ekinezgi/Documents/FerryProject/2017JanMar_Trip.csv'\n",
    "\n",
    "\n",
    "#     MergeFiles(vFilesPath, vOrigData)                    # Read vessel json files and append to orig file\n",
    "    dfx = CleanOrigData(vOrigData, vAllTrip, vDockLatLon)  # Clean vessel orig file and save to vCleanData\n",
    "    dfy = RemoveProblemTrips(dfx, vStartD, vEndD)\n",
    "    CreateFerryData(dfy, vCleanData)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    print('Start Time :', time.ctime())\n",
    "    run()\n",
    "    \n",
    "    end = time.time()\n",
    "    tot_time = end - start\n",
    "    print('Total time used :', tot_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
